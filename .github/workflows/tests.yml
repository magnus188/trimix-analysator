name: Trimix Analyzer CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
    types: [opened, synchronize, reopened, ready_for_review]

env:
  TRIMIX_ENVIRONMENT: test
  TRIMIX_MOCK_SENSORS: true

jobs:
  # Comprehensive tests that run on main branch or when specifically requested
  comprehensive-tests:
    name: Comprehensive Tests
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || contains(github.event.pull_request.labels.*.name, 'run-full-tests')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-py3.11-pip-${{ hashFiles('**/requirements-dev.txt', '**/requirements-base.txt') }}

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y xvfb libgl1-mesa-dev libglib2.0-0

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-base.txt
        pip install -r requirements-dev.txt
        # Install specific garden packages using pip instead of garden command
        pip install kivy-garden.graph

    - name: Set environment for testing
      run: |
        echo "DISPLAY=:99.0" >> $GITHUB_ENV

    - name: Start virtual display
      run: |
        Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &
        sleep 2

    - name: Run all tests with coverage
      run: |
        python -m pytest tests/ --cov=. --cov-report=xml --cov-report=html --cov-report=term-missing --tb=short
      env:
        PYTHONPATH: .

    - name: Run slow tests
      run: |
        python -m pytest tests/ -v -m "slow" --tb=short
      env:
        PYTHONPATH: .

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: comprehensive
        name: codecov-comprehensive
        fail_ci_if_error: false

    - name: Archive coverage reports
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report
        path: htmlcov/

  # Security and quality checks
  security-checks:
    name: Security & Quality
    runs-on: ubuntu-latest
    if: github.event.pull_request.draft == false
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
        pip install safety bandit  # Ensure security tools are available

    - name: Run security checks with bandit
      run: |
        bandit -r . -f json -o bandit-report.json \
          --exclude ./utils/update_manager.py \
          --severity-level high || true
        bandit -r . \
          --exclude ./utils/update_manager.py \
          --severity-level high || echo "Security scan completed with warnings"

    - name: Run safety check
      run: |
        safety check --json --output safety-report.json || true
        safety check

    - name: Upload security reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  # Type checking
  type-check:
    name: Type Checking
    runs-on: ubuntu-latest
    if: github.event.pull_request.draft == false
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-base.txt
        pip install mypy

    - name: Run type checking
      run: |
        mypy . --ignore-missing-imports --no-strict-optional || true

  # Test results summary
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [security-checks, type-check]
    if: always() && github.event.pull_request.draft == false
    
    steps:
    - name: Generate summary
      run: |
        echo "# 🧪 Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Security Checks: ${{ needs.security-checks.result }}" >> $GITHUB_STEP_SUMMARY
        echo "## Type Checking: ${{ needs.type-check.result }}" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ needs.security-checks.result }}" = "success" ] && \
           [ "${{ needs.type-check.result }}" = "success" ]; then
          echo "✅ All checks passed! Ready for review." >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Some checks failed. Please review the results above." >> $GITHUB_STEP_SUMMARY
        fi

  build-test:
    runs-on: ubuntu-latest
    needs: [type-check]
    if: github.event_name == 'pull_request'
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y xvfb libgl1-mesa-dev libglib2.0-0 libmtdev1

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
        # Install specific garden packages
        pip install kivy-garden.graph

    - name: Set environment for testing
      run: |
        echo "TRIMIX_MOCK_SENSORS=1" >> $GITHUB_ENV
        echo "TRIMIX_ENVIRONMENT=test" >> $GITHUB_ENV
        echo "DISPLAY=:99.0" >> $GITHUB_ENV

    - name: Start virtual display
      run: |
        Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &
        sleep 2

    - name: Test application import
      run: |
        python -c "
        import sys
        sys.path.insert(0, '.')
        try:
            from main import TrimixApp
            app = TrimixApp()
            print('✅ Application import successful')
        except Exception as e:
            print(f'❌ Application import failed: {e}')
            sys.exit(1)
        "

    - name: Test database functionality
      run: |
        python -c "
        import sys
        sys.path.insert(0, '.')
        from utils.database_manager import db_manager
        
        # Test basic database operations
        db_manager.set_setting('test', 'ci_test', 'success')
        result = db_manager.get_setting('test', 'ci_test')
        assert result == 'success', f'Expected success, got {result}'
        print('✅ Database functionality test passed')
        "

    - name: Test sensor interface
      run: |
        python -c "
        import sys
        sys.path.insert(0, '.')
        from utils.sensor_interface import get_sensors, get_readings
        
        # Test sensor interface
        sensors = get_sensors()
        readings = get_readings()
        assert isinstance(readings, dict), 'Readings should be a dictionary'
        assert len(readings) > 0, 'Should have some sensor readings'
        print('✅ Sensor interface test passed')
        "

  # Performance testing job (optional, runs on develop branch)
  performance:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
        pip install pytest-benchmark
        # Install specific garden packages
        pip install kivy-garden.graph

    - name: Set environment for testing
      run: |
        echo "TRIMIX_MOCK_SENSORS=1" >> $GITHUB_ENV
        echo "TRIMIX_ENVIRONMENT=test" >> $GITHUB_ENV

    - name: Run performance tests
      run: |
        pytest tests/ -v -m "slow" --benchmark-only --benchmark-sort=mean

    - name: Upload performance results
      uses: actions/upload-artifact@v4
      with:
        name: performance-results
        path: .benchmarks/
